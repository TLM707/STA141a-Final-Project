---
title: "Neural Spike Analysis Project"
author: "Taige Mueller"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup_code, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Libraries, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(tidyverse)
library(caret)
library(xgboost)
library(pROC)
library(tibble)
library(RColorBrewer)
library(explore)
library(ggridges)
library(data.table)
library(gridExtra)
```

```{r Import, include=FALSE}
session <-list()
for(i in 1:18){
  session[[i]]=readRDS(paste('/Users/taige/Desktop/STA141AProject/Data/session',i,'.rds',sep=''))
   print(session[[i]]$mouse_name)
   print(session[[i]]$date_exp)
}

ls(session[[1]])
summary(session[[1]]$brain_area)
table(session[[1]]$brain_area)

# summary(session[[18]])
```

```{r Create_HTML_File, include=FALSE}
# rmarkdown::render("STA141aFinalProject.rmd")
```

### Abstract

##### This study done on mice is an important look into how visual stimulus is treated by the brain. Through experiments of placing Neuropixels probes into brain areas, we studied neurons and their response to the visual stimulant. Our study had variety over the number of sessions and trials given to each mice. We ound that there's a significant success rate, suggesting impact and importance.

### Session 1 Introduction

##### Our study examines how brain activity and visual stimuli influence decision-making success in mice. Success is defined by the mice performing the desired action in response to visual cues.

##### In the experiment, mice were positioned with their front paws on a wheel, which they could rotate left or right. Visual stimuli were presented on boards with varying contrasts on the left and right sides. The goal was to determine whether the mice could make the correct decision based on these stimuli.

##### To analyze the factors influencing success or failure, we measured several key variables, including left contrast, right contrast, time bins for neural spikes, neural activity in the visual cortex, and the brain area involved.

##### For this report, we focus on four mice, Cori, Forssmann, Hench, and Lederberg. Each of whom participated in multiple testing sessions over 3 to 7 days. Cori had 3 sessions, Forssmann had 4, Hench had 4, and Lederberg had 7. Our objective is to investigate what impacts the success rate of correct decisions and how the recorded neural activity contributes to this outcome. We will conduct statistical analyses and explore our findings to gain deeper insights into this decision-making process.

### Session 2 Exploratory Analysis

##### In analyzing our data we found that the overall success rate accross all 18 sessions was 71%. This is a good percentage. It shows that the contrasts likely do have an important impact on the decision-making of the mice. We also found that there were 62 unique brain regions that were studied. The top five brain regions with the most neurons were root, TH, CA1, VISp and MOs. With root far exceeding the rest.


```{r variables, include=FALSE}
names(session[[1]])
```


```{r Session 1 Info, include=FALSE}
dim(session[[1]]$spks[[1]])
length(session[[1]]$brain_area)
session[[1]]$spks[[1]][6,]
```

```{r Overall success rate, include=FALSE}
n.session=length(session)

n_success = 0
n_trial = 0
for(i in 1:n.session){
    tmp = session[[i]];
    n_trial = n_trial + length(tmp$feedback_type);
    n_success = n_success + sum(tmp$feedback_type == 1);
}
n_success/n_trial
```


```{r Number of unique brain areas, include=FALSE}
unique_brain_areas <- unique(unlist(lapply(session, function(x) tolower(trimws(x$brain_area)))))
length(unique_brain_areas)  
print(unique_brain_areas) 
```


```{r Number of neurons recorded per brain area accross sessions, include=FALSE}
brain_area_counts <- data.frame(
  brain_area = unlist(lapply(session, function(x) x$brain_area)),  # Extract all brain areas
  session_ID = rep(1:18, times = sapply(session, function(x) length(x$brain_area)))  # Assign session IDs
) %>%
  group_by(brain_area) %>%
  summarise(num_neurons = n()) %>%
  arrange(desc(num_neurons))  # Sort by highest count

# Print results
print(brain_area_counts)
```

```{r Graph trials per session, echo=FALSE, message=FALSE, warning=FALSE}
trial_counts <- sapply(session, function(x) length(x$feedback_type))
neuron_counts <- sapply(session, function(x) length(unique(x$brain_area)))
brain_area_counts <- sapply(session, function(x) length(unique(x$brain_area)))

# Create a summary table
eda_summary <- data.frame(
  session_ID = 1:18,
  num_trials = trial_counts,
  num_neurons = neuron_counts,
  num_brain_areas = brain_area_counts
)

# print(eda_summary)

muted_colors <- c( "#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FDBF6F", "#FF7F00",
  "#C6DBEF", "#6BAED6", "#D9F0A3", "#78C679", "#FDD49E", "#FE9929",
  "#FC9272", "#DE2D26", "#E5F5E0", "#A1D99B", "#FFD700", "#FFA500"
)

ggplot(eda_summary, aes(x = factor(session_ID), y = num_trials, fill = factor(session_ID))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = muted_colors) +
  labs(title = "Number of Trials Per Session", x = "Session ID", y = "Number of Trials") +
  theme_minimal()
```

##### The above graph shows that the number of trials per session and mouse varied significantly.

```{r Graph Heatmap of brain areas with recorded neurons, echo=FALSE, message=FALSE, warning=FALSE}

# Prepare data: Count the number of neurons per brain area per session
brain_area_per_session <- data.frame(
  session_ID = rep(1:18, times = sapply(session, function(x) length(x$brain_area))),
  brain_area = unlist(lapply(session, function(x) x$brain_area))
) %>%
  group_by(session_ID, brain_area) %>%
  summarise(num_neurons = n(), .groups = "drop")

# Plot heatmap
ggplot(brain_area_per_session, aes(x = factor(session_ID), y = brain_area, fill = factor(session_ID))) +
  geom_tile() +
  scale_fill_manual(values = muted_colors) +  # Assign muted colors per session
  labs(title = "Neuron Counts Per Brain Area Across Sessions",
       x = "Session ID", y = "Brain Area", fill = "Session") +
  theme_minimal()
```

##### The brain areas also varied greatly accross the sessions. With some being much more popular than others. This heatmap graph shows how different each session was. This confirms that root was a common brain area for neurons accross the sessions. We can see it trace accross the sessions.

##### Our success rates accross the sessions varied there was a slight upward trend of higher percentages towards the later sessions. This may be due to the on-average higher traial count as well.

```{r Percentage of success over trials, include=FALSE}
# Initialize an empty dataframe to store results
session_success <- tibble(
  session_ID = integer(),
  total_trials = integer(),
  successful_trials = integer(),
  success_percentage = numeric()
)

# Loop through each session and calculate success percentage
n.session <- length(session)
for(i in 1:n.session){
    tmp <- session[[i]]  # Extract session data
    
    # Ensure feedback_type exists in the session data
    if(!is.null(tmp$feedback_type) && length(tmp$feedback_type) > 0) {
        total_trials <- length(tmp$feedback_type)  # Count total trials
        successful_trials <- sum(tmp$feedback_type == 1)  # Count successes

        # Compute success percentage safely
        success_percentage <- ifelse(total_trials > 0, (successful_trials / total_trials) * 100, 0)

        # Store results
        session_success <- bind_rows(session_success, tibble(
          session_ID = i,
          total_trials = total_trials,
          successful_trials = successful_trials,
          success_percentage = success_percentage
        ))
    }
}

print(session_success)
```

```{r Graph Percentage of Success per mouse per session, echo=FALSE, message=FALSE, warning=FALSE}
session_success <- session_success %>%
  mutate(mouse_name = case_when(
    session_ID %in% 1:3 ~ "Cori",
    session_ID %in% 4:7 ~ "Forssmann",
    session_ID %in% 8:11 ~ "Hench",
    session_ID %in% 12:18 ~ "Lederberg"
  ))

ggplot(session_success, aes(x = factor(session_ID), y = success_percentage, fill = mouse_name)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("Cori" = "#A6CEE3", 
                               "Forssmann" = "#B2DF8A", 
                               "Hench" = "#FDBF6F", 
                               "Lederberg" = "#DE2D26")) +  # Assign specific colors per mouse
  labs(title = "Success Percentage Per Session (Grouped by Mouse)",
       x = "Session ID",
       y = "Success Percentage (%)",
       fill = "Mouse") +
  theme_minimal() +
  geom_text(aes(label = round(success_percentage, 1)), vjust = -0.5, size = 4)
```
##### The mouse, Lederberg had the highest overall percentage of successes with Cori having the lowest. This further suggests that number of trials and sessions may impact success rate.


```{r Graph Average success rate per mouse, echo=FALSE, message=FALSE, warning=FALSE}
mouse_success <- session_success %>%
  group_by(mouse_name) %>%
  summarise(avg_success_rate = mean(success_percentage, na.rm = TRUE))

ggplot(mouse_success, aes(x = mouse_name, y = avg_success_rate, fill = mouse_name)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("Cori" = "#A6CEE3", 
                               "Forssmann" = "#B2DF8A", 
                               "Hench" = "#FDBF6F", 
                               "Lederberg" = "#DE2D26")) +  # Assign colors per mouse
  labs(title = "Average Success Percentage Per Mouse",
       x = "Mouse",
       y = "Average Success Percentage (%)",
       fill = "Mouse") +
  theme_minimal() +
  geom_text(aes(label = round(avg_success_rate, 1)), vjust = -0.5, size = 5)
```

```{r Graph Number of trials per session, echo=FALSE, message=FALSE, warning=FALSE}
trial_counts <- sapply(session, function(x) length(x$feedback_type))

# Create a DataFrame
trial_df <- data.frame(
  session_ID = 1:18,
  num_trials = trial_counts
)

# Graph
ggplot(trial_df, aes(x = factor(session_ID), y = num_trials, fill = factor(session_ID))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = muted_colors) +  # Apply custom color palette
  labs(title = "Number of Trials Per Session",
       x = "Session ID", y = "Number of Trials", fill = "Session ID") +
  theme_minimal() +
  geom_text(aes(label = num_trials), vjust = -0.5, size = 4)
```

##### Above is a graph showing the number of trials per session.

```{r Graph Number of sessions per mouse, echo=FALSE, message=FALSE, warning=FALSE}
trial_per_mouse <- data.frame(
  session_ID = 1:18,
  mouse_name = sapply(session, function(x) unique(x$mouse_name)),  # Extract unique mouse names
  num_trials = sapply(session, function(x) length(x$feedback_type))
)

# Aggregate the total number of trials per mouse
mouse_trial_counts <- trial_per_mouse %>%
  group_by(mouse_name) %>%
  summarise(total_trials = sum(num_trials))

# Define mouse-specific colors (ensure these match previous graphs)
mouse_colors <- c(
  "Cori" = "#A6CEE3",       # Light Blue
  "Forssmann" = "#B2DF8A",  # Light Green
  "Hench" = "#FDBF6F",      # Orange
  "Lederberg" = "#DE2D26"   # Dark Orange
)

# Graph with correctly mapped colors
ggplot(mouse_trial_counts, aes(x = mouse_name, y = total_trials, fill = mouse_name)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = mouse_colors) +  # Explicitly assign colors per mouse
  labs(title = "Number of Trials Per Mouse",
       x = "Mouse Name", y = "Total Number of Trials", fill = "Mouse") +
  theme_minimal() +
  geom_text(aes(label = total_trials), vjust = -0.5, size = 5)
```

##### The number of trials varied greatly between the four mice. This may influence the success rate and other outcomes of study.

### Session 3 Data Integration

##### Next we modified the data in preparation to prep it for model training. We used normalization. This step was simple and represents a base to our analysis.

```{r Z-Score Normalization, include=FALSE}
normalize_spikes <- function(spike_matrix) {
  apply(spike_matrix, 1, function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))
}

# Apply normalization across all trials in each session
for (i in 1:18) {
  session[[i]]$spks <- lapply(session[[i]]$spks, normalize_spikes)
}
```

```{r Trial Features, include=FALSE}
compute_trial_features <- function(spike_matrix) {
  data.frame(
    mean_firing_rate = rowMeans(spike_matrix, na.rm = TRUE),
    peak_firing_time = apply(spike_matrix, 1, function(x) which.max(x)),
    variance_firing = apply(spike_matrix, 1, var, na.rm = TRUE)
  )
}

# Apply across all sessions
for (i in 1:18) {
  session[[i]]$trial_features <- lapply(session[[i]]$spks, compute_trial_features)
}
```


### Section 4 Predictive Modeling

##### Next we built our predictive model. We merged the dataset to format. Using PCA and XGBoost Model Training.

```{r Aggregate Session-Level Features, include=FALSE}
# Extract session-level information
session_info <- tibble(
  session_ID = 1:18,
  mouse_name = sapply(session, function(x) unique(x$mouse_name)),
  avg_neuron_spike_rate = sapply(session, function(x) mean(unlist(x$spks), na.rm = TRUE)),
  num_neurons = sapply(session, function(x) length(unique(x$brain_area)))
)

# Convert `mouse_name` to factor
session_info$mouse_name <- as.factor(session_info$mouse_name)

# One-hot encode brain areas
brain_areas <- unique(unlist(lapply(session, function(x) unique(x$brain_area))))
for (area in brain_areas) {
  session_info[[paste0("brain_", area)]] <- sapply(session, function(x) as.integer(area %in% x$brain_area))
}
```

```{r Merge Trial-Level Data, include=FALSE}
all_trials_df <- bind_rows(lapply(1:18, function(i) {
  data.frame(
    session_ID = i,
    contrast_left = session[[i]]$contrast_left,
    contrast_right = session[[i]]$contrast_right,
    feedback_type = ifelse(session[[i]]$feedback_type == -1, 0, 1), # Convert -1 to 0
    avg_neuron_spike_rate = session_info$avg_neuron_spike_rate[i],
    num_neurons = session_info$num_neurons[i]
  )
}))

# Convert `feedback_type` to an integer (binary classification)
all_trials_df$feedback_type <- as.integer(all_trials_df$feedback_type)
```

```{r Merge Session-Level Data Into Final Dataset, include=FALSE}
final_dataset <- all_trials_df %>%
  left_join(session_info, by = "session_ID") %>%
  mutate(
    session_ID = as.factor(session_ID), 
    mouse_name = as.factor(mouse_name)
  )

# Check structure
str(final_dataset)
```

```{r Train-Test Split, include=FALSE}
set.seed(42)  # Ensure reproducibility
trainIndex <- createDataPartition(final_dataset$feedback_type, p = 0.7, list = FALSE)

train_data <- final_dataset[trainIndex, ]
test_data  <- final_dataset[-trainIndex, ]

# Check dataset sizes
print(dim(train_data))
print(dim(test_data))
```

```{r Principal Component Analysis (PCA), echo=FALSE, message=FALSE, warning=FALSE}
# Identify brain area columns (one-hot encoded)
brain_area_columns <- grep("^brain_", names(final_dataset), value = TRUE)

# Extract only brain area data for PCA
brain_area_data <- final_dataset[, brain_area_columns]

# Replace NA values with 0
brain_area_data[is.na(brain_area_data)] <- 0  

# Perform PCA
pca_result <- prcomp(brain_area_data, center = TRUE, scale. = TRUE)

# Check variance explained
# summary(pca_result)

# Scree plot to visualize variance per component
plot(pca_result, type = "lines")

# Select first 5 principal components
pca_components <- as.data.frame(pca_result$x[, 1:5])
colnames(pca_components) <- paste0("PC", 1:5)

# Add PCA components to dataset
final_dataset <- cbind(final_dataset, pca_components)

# Drop original brain area columns
final_dataset <- final_dataset %>% select(-all_of(brain_area_columns))
```


```{r XGBoost Model Training, include=FALSE}
# Select relevant predictors (Now includes PCA)
predictors <- c("contrast_left", "contrast_right", "avg_neuron_spike_rate.x")  # Use the correct column name

# Convert train and test data to matrices
train_matrix <- as.matrix(train_data[, predictors, drop = FALSE])
test_matrix <- as.matrix(test_data[, predictors, drop = FALSE])

# Convert to XGBoost DMatrix
dtrain <- xgb.DMatrix(data = train_matrix, label = train_data$feedback_type)
dtest <- xgb.DMatrix(data = test_matrix, label = test_data$feedback_type)

# Create DMatrix for XGBoost
dtrain <- xgb.DMatrix(data = train_matrix, label = train_data$feedback_type)
dtest <- xgb.DMatrix(data = test_matrix, label = test_data$feedback_type)

# Define XGBoost parameters
params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  max_depth = 6,
  eta = 0.1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

# Train XGBoost model
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 10
)

# Print model summary
print(xgb_model)
```

```{r Model Prediction and Evaluation, echo=FALSE, message=FALSE, warning=FALSE}
# Make predictions
pred_probs <- predict(xgb_model, dtest)
pred_labels <- ifelse(pred_probs > 0.5, 1, 0)

# Calculate accuracy
accuracy <- mean(pred_labels == test_data$feedback_type)
print(paste("Test Accuracy:", round(accuracy * 100, 2), "%"))

# Confusion Matrix
conf_matrix <- table(Predicted = pred_labels, Actual = test_data$feedback_type)
print(conf_matrix)

# ROC Curve & AUC
roc_curve <- roc(test_data$feedback_type, pred_probs)
auc_value <- auc(roc_curve)

# Plot ROC Curve
plot(roc_curve, col = "#1F78B4", main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
```


### Session 5 Test Data

##### This section was unsuccessful due to constraints. My laptop was not handling the code for this project well. It kept getting stuck loading and would take a while to run. I tried to use my prediction model on the test data, however the test data was not matching the layout of my model. I attempted to fix this, however, it was not resolved in time. Going forward I would fix the layout issue. This would likely conclude in a successful run of the emodel on the provided test data.

```{r Import Test Data, include=FALSE}
# # Define test folder path
# test_folder <- "/Users/taige/Desktop/STA141AProject/test/"
# 
# # Read test sessions
# test_sessions <- list()
# test_files <- c("test1.rds", "test2.rds")  # Test session filenames
# 
# for (i in seq_along(test_files)) {
#   test_sessions[[i]] <- readRDS(paste0(test_folder, test_files[i]))
# }
# 
# # Check structure of the first test session
# str(test_sessions[[1]])
```


```{r Convert test data}
# # Convert test data into a dataframe for predictions
# test_trials_df <- bind_rows(lapply(seq_along(test_sessions), function(i) {
#   data.frame(
#     session_ID = i + 18,  # Assign new session IDs (assuming training data had 18 sessions)
#     contrast_left = test_sessions[[i]]$contrast_left,
#     contrast_right = test_sessions[[i]]$contrast_right,
#     avg_neuron_spike_rate = mean(unlist(test_sessions[[i]]$spks), na.rm = TRUE),
#     num_neurons = length(unique(test_sessions[[i]]$brain_area))
#   )
# }))
# 
# # Check test data structure
# print(head(test_trials_df))
# 
# 
# # Select same predictors used in training
# predictors <- c("contrast_left", "contrast_right", "avg_neuron_spike_rate")
# 
# # Convert test data to matrix
# test_matrix <- as.matrix(test_trials_df[, predictors])
# 
# # Create XGBoost DMatrix
# dtest_new <- xgb.DMatrix(data = test_matrix)
```


```{r Predictions on test data, include=FALSE}
# # Ensure test data has the same feature columns as train data
# test_matrix_fixed <- test_matrix[, train_features, drop = FALSE]
# 
# # Add missing columns with zeros
# for (col in setdiff(train_features, colnames(test_matrix_fixed))) {
#   test_matrix_fixed[, col] <- 0  # Assign 0 to missing features
# }
# 
# # Convert to XGBoost DMatrix
# dtest_new <- xgb.DMatrix(data = test_matrix_fixed)
# 
# # Make predictions
# predictions <- predict(xgb_model, dtest_new)
# 
# # Predict feedback_type on new test data
# predictions <- predict(xgb_model, dtest_new)
# 
# # Convert probabilities to binary (1 = success, 0 = failure)
# predicted_feedback <- ifelse(predictions > 0.5, 1, 0)
# 
# # Add predictions to test data
# test_trials_df$predicted_feedback <- predicted_feedback
# 
# # Print results
# print(test_trials_df[, c("session_ID", "contrast_left", "contrast_right", "predicted_feedback")])
# 
# # Check feature names used in training
# train_features <- colnames(train_matrix)
# 
# # Check feature names in test data
# test_features <- colnames(test_matrix)
# 
# # Compare
# setdiff(train_features, test_features)  # Features missing in test
# setdiff(test_features, train_features)  # Extra features in test
```

### Discussion

##### This report is far from thurough. However we gained valuable insights and have a direction moving forward. We found that visual stimulus impacts neurons accross brain regions. Not sticking to solely visual neuron spaces. We also observed that there seemed to be a relationship between number of sessions and trials with the overall success rate. Though this is not a very large difference, it is still present. Our trained model was not very accurate, however, it likely would have adapted to new data well if we were able to use it on the test data.

### acknowledgements

##### https://chatgpt.com/share/67d8b3f7-7218-8001-ae9f-dfbc90b6a2b3


#### Study Paper
##### https://discovery.ucl.ac.uk/id/eprint/10087006/1/Steinmetz%20et%20al%202019%20-%20Revised%20Manuscript.pdf




