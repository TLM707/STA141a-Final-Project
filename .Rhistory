)
# Function to extract and process spiking data
process_spikes <- function(sessions, mouse_name) {
# Extract spiking data for all trials in selected sessions
spike_data <- rbindlist(lapply(sessions, function(i) {
trials <- seq_along(session[[i]]$spks)  # Get all trials in session
# Flatten and extract all trials for session `i`
rbindlist(lapply(trials, function(t) {
mat <- as.data.table(session[[i]]$spks[[t]])  # Convert matrix to data.table
mat[, neuron := .I]  # Create neuron index column
mat <- melt(mat, id.vars = "neuron", variable.name = "time_bin", value.name = "spike_count")  # Wide to long
mat[, `:=`(feedback_type = session[[i]]$feedback_type[t], session_ID = i, mouse_name = mouse_name)]
return(mat)
}))
}))
# Convert time_bin (V1, V2...) to numeric
spike_data[, time_bin := as.numeric(gsub("V", "", time_bin))]
# Compute average spike count per time bin for each feedback type
psth_data <- spike_data[, .(avg_spike_count = mean(spike_count, na.rm = TRUE)), by = .(time_bin, feedback_type)]
return(psth_data)
}
# Generate PSTH plots for each mouse
psth_plots <- lapply(names(mice_sessions), function(mouse) {
psth_data <- process_spikes(mice_sessions[[mouse]], mouse)
p <-  ggplot(psth_data, aes(x = time_bin, y = avg_spike_count, color = factor(feedback_type))) +
geom_line(size = 1) +
scale_color_manual(values = c("#DE2D26", "#1F78B4"), labels = c("Failure", "Success")) +
labs(title = paste("Peri-Stimulus Time Histogram (PSTH) -", mouse),
x = "Time Bins", y = "Average Spike Count", color = "Feedback Type") +
theme_minimal()
})
print(p)
}
# Define mice session groups
mice_sessions <- list(
"Cori" = 1:3,
"Forssmann" = 4:7,
"Hench" = 8:11,
"Lederberg" = 12:18
)
# Function to extract and process spiking data
process_spikes <- function(sessions, mouse_name) {
# Extract spiking data for all trials in selected sessions
spike_data <- rbindlist(lapply(sessions, function(i) {
trials <- seq_along(session[[i]]$spks)  # Get all trials in session
# Flatten and extract all trials for session `i`
rbindlist(lapply(trials, function(t) {
mat <- as.data.table(session[[i]]$spks[[t]])  # Convert matrix to data.table
mat[, neuron := .I]  # Create neuron index column
mat <- melt(mat, id.vars = "neuron", variable.name = "time_bin", value.name = "spike_count")  # Wide to long
mat[, `:=`(feedback_type = session[[i]]$feedback_type[t], session_ID = i, mouse_name = mouse_name)]
return(mat)
}))
}))
# Convert time_bin (V1, V2...) to numeric
spike_data[, time_bin := as.numeric(gsub("V", "", time_bin))]
# Compute average spike count per time bin for each feedback type
psth_data <- spike_data[, .(avg_spike_count = mean(spike_count, na.rm = TRUE)), by = .(time_bin, feedback_type)]
return(psth_data)
}
# Generate PSTH plots for each mouse
psth_plots <- lapply(names(mice_sessions), function(mouse) {
psth_data <- process_spikes(mice_sessions[[mouse]], mouse)
p <-  ggplot(psth_data, aes(x = time_bin, y = avg_spike_count, color = factor(feedback_type))) +
geom_line(size = 1) +
scale_color_manual(values = c("#DE2D26", "#1F78B4"), labels = c("Failure", "Success")) +
labs(title = paste("Peri-Stimulus Time Histogram (PSTH) -", mouse),
x = "Time Bins", y = "Average Spike Count", color = "Feedback Type") +
theme_minimal()
})
print(p)
# Define mice session groups
mice_sessions <- list(
"Cori" = 1:3,
"Forssmann" = 4:7,
"Hench" = 8:11,
"Lederberg" = 12:18
)
# Function to extract and process spiking data
process_spikes <- function(sessions, mouse_name) {
# Extract spiking data for all trials in selected sessions
spike_data <- rbindlist(lapply(sessions, function(i) {
trials <- seq_along(session[[i]]$spks)  # Get all trials in session
# Flatten and extract all trials for session `i`
rbindlist(lapply(trials, function(t) {
mat <- as.data.table(session[[i]]$spks[[t]])  # Convert matrix to data.table
mat[, neuron := .I]  # Create neuron index column
mat <- melt(mat, id.vars = "neuron", variable.name = "time_bin", value.name = "spike_count")  # Wide to long
mat[, `:=`(feedback_type = session[[i]]$feedback_type[t], session_ID = i, mouse_name = mouse_name)]
return(mat)
}))
}))
# Convert time_bin (V1, V2...) to numeric
spike_data[, time_bin := as.numeric(gsub("V", "", time_bin))]
# Compute average spike count per time bin for each feedback type
psth_data <- spike_data[, .(avg_spike_count = mean(spike_count, na.rm = TRUE)), by = .(time_bin, feedback_type)]
return(psth_data)
}
# Generate PSTH plots for each mouse
psth_plots <- lapply(names(mice_sessions), function(mouse) {
psth_data <- process_spikes(mice_sessions[[mouse]], mouse)
# Plot with two lines (one for each feedback type)
ggplot(psth_data, aes(x = time_bin, y = avg_spike_count, color = factor(feedback_type))) +
geom_line(size = 1) +
scale_color_manual(values = c("#DE2D26", "#1F78B4"), labels = c("Failure", "Success")) +
labs(title = paste("Peri-Stimulus Time Histogram (PSTH) -", mouse),
x = "Time Bins", y = "Average Spike Count", color = "Feedback Type") +
theme_minimal()
})
# Display the plots
psth_plots
# Load necessary libraries
library(xgboost)
library(caret)
library(pROC)
# Load and preprocess the training data (assuming it's already done)
# train_data <- ...
# Select relevant predictors
predictors <- c("contrast_left", "contrast_right", "avg_neuron_spike_rate.x")
# Convert train data to a matrix
train_matrix <- as.matrix(train_data[, predictors, drop = FALSE])
# Convert to XGBoost DMatrix
dtrain <- xgb.DMatrix(data = train_matrix, label = train_data$feedback_type)
# Define XGBoost parameters
params <- list(
objective = "binary:logistic",
eval_metric = "logloss",
max_depth = 6,
eta = 0.1,
subsample = 0.8,
colsample_bytree = 0.8
)
# Train XGBoost model
xgb_model <- xgb.train(
params = params,
data = dtrain,
nrounds = 100,
watchlist = list(train = dtrain),
early_stopping_rounds = 10
)
# Print model summary
print(xgb_model)
# Load and preprocess the test data
test_folder <- "~/Desktop/STA141aProject/test"
test_files <- list.files(test_folder, pattern = "\\.csv$", full.names = TRUE)
test_data_list <- lapply(test_files, read.csv)
test_data <- do.call(rbind, test_data_list)
# Ensure the test data has the same structure as the training data
test_data$feedback_type <- as.factor(test_data$feedback_type)
# Prepare the test data for XGBoost
test_matrix <- as.matrix(test_data[, predictors, drop = FALSE])
# Define test folder path
test_folder <- "/Users/taige/Desktop/STA141AProject/test/"
# Read test sessions
test_sessions <- list()
for (i in 1:2) {  # Assuming 2 test sessions
test_sessions[[i]] <- readRDS(paste0(test_folder, "session", i, ".rds"))
}
# Define test folder path
test_folder <- "/Users/taige/Desktop/STA141AProject/test/"
# Read test sessions
test_sessions <- list()
test_files <- c("test1.rds", "test2.rds")  # Test session filenames
for (i in seq_along(test_files)) {
test_sessions[[i]] <- readRDS(paste0(test_folder, test_files[i]))
}
# Check structure of the first test session
str(test_sessions[[1]])
# Convert test data into a dataframe for predictions
test_trials_df <- bind_rows(lapply(seq_along(test_sessions), function(i) {
data.frame(
session_ID = i + 18,  # Assign new session IDs (assuming training data had 18 sessions)
contrast_left = test_sessions[[i]]$contrast_left,
contrast_right = test_sessions[[i]]$contrast_right,
avg_neuron_spike_rate = mean(unlist(test_sessions[[i]]$spks), na.rm = TRUE),
num_neurons = length(unique(test_sessions[[i]]$brain_area))
)
}))
# Check test data structure
print(head(test_trials_df))
# Convert test data into a dataframe for predictions
test_trials_df <- bind_rows(lapply(seq_along(test_sessions), function(i) {
data.frame(
session_ID = i + 18,  # Assign new session IDs (assuming training data had 18 sessions)
contrast_left = test_sessions[[i]]$contrast_left,
contrast_right = test_sessions[[i]]$contrast_right,
avg_neuron_spike_rate = mean(unlist(test_sessions[[i]]$spks), na.rm = TRUE),
num_neurons = length(unique(test_sessions[[i]]$brain_area))
)
}))
# Check test data structure
print(head(test_trials_df))
# Select same predictors used in training
predictors <- c("contrast_left", "contrast_right", "avg_neuron_spike_rate")
# Convert test data to matrix
test_matrix <- as.matrix(test_trials_df[, predictors])
# Create XGBoost DMatrix
dtest_new <- xgb.DMatrix(data = test_matrix)
# Predict feedback_type on new test data
predictions <- predict(xgb_model, dtest_new)
# Check feature names used in training
train_features <- colnames(train_matrix)
# Check feature names in test data
test_features <- colnames(test_matrix)
# Compare
setdiff(train_features, test_features)  # Features missing in test
setdiff(test_features, train_features)  # Extra features in test
# Convert probabilities to binary (1 = success, 0 = failure)
predicted_feedback <- ifelse(predictions > 0.5, 1, 0)
# Predict feedback_type on new test data
predictions <- predict(xgb_model, dtest_new)
# Rename the column in test data to match training data
colnames(test_matrix)[colnames(test_matrix) == "avg_neuron_spike_rate"] <- "avg_neuron_spike_rate.x"
# Predict feedback_type on new test data
predictions <- predict(xgb_model, dtest_new)
predictions <- predict(xgb_model, dtest_new)
xgb_model
dtest_new
# Predict feedback_type on new test data
predictions <- predict(xgb_model, dtest_new)
# Convert test data into a dataframe for predictions
test_trials_df <- bind_rows(lapply(seq_along(test_sessions), function(i) {
data.frame(
session_ID = i + 18,  # Assign new session IDs (assuming training data had 18 sessions)
contrast_left = test_sessions[[i]]$contrast_left,
contrast_right = test_sessions[[i]]$contrast_right,
avg_neuron_spike_rate = mean(unlist(test_sessions[[i]]$spks), na.rm = TRUE),
num_neurons = length(unique(test_sessions[[i]]$brain_area))
)
}))
# Check test data structure
print(head(test_trials_df))
# Select same predictors used in training
predictors <- c("contrast_left", "contrast_right", "avg_neuron_spike_rate")
# Convert test data to matrix
test_matrix <- as.matrix(test_trials_df[, predictors])
# Create XGBoost DMatrix
dtest_new <- xgb.DMatrix(data = test_matrix)
# Predict feedback_type on new test data
predictions <- predict(xgb_model, dtest_new)
# Ensure test data has the same feature columns as train data
test_matrix_fixed <- test_matrix[, train_features, drop = FALSE]
dim(session[[1]]$spks[[1]])
length(session[[1]]$brain_area)
session[[1]]$spks[[1]][6,]
get_trail_data <- function(session_id, trail_id){
spikes <- session[[session_id]]$spks[[trail_id]]
if (any(is.na(spikes))) {
disp("value missing")
}
trail_tibble <- tibble(neuron_spike = rowSums(spikes)) %>%
add_column(brain_area = session[[session_id]]$brain_area) %>%
group_by(brain_area) %>%
summarize(
region_sum_spike = sum(neuron_spike),
region_count = n(),
region_mean_spike = mean(neuron_spike)
)
trail_tibble <- trail_tibble %>%
add_column(trail_id = trail_id) %>%
add_column(contrast_left = session[[session_id]]$contrast_left[trail_id]) %>%
add_column(contrast_right = session[[session_id]]$contrast_right[trail_id]) %>%
add_column(feedback_type = session[[session_id]]$feedback_type[trail_id])
trail_tibble
}
trail_tibble_1_2 <- get_trail_data(1,2)
get_trail_data <- function(session_id, trail_id){
spikes <- session[[session_id]]$spks[[trail_id]]
if (any(is.na(spikes))) {
message("Value missing in spikes for session ", session_id, ", trial ", trail_id)
}
trail_tibble <- tibble(neuron_spike = rowSums(spikes, na.rm = TRUE)) %>%
add_column(brain_area = session[[session_id]]$brain_area) %>%
group_by(brain_area) %>%
summarize(
region_sum_spike = sum(neuron_spike, na.rm = TRUE),
region_count = n(),
region_mean_spike = mean(neuron_spike, na.rm = TRUE)
)
trail_tibble <- trail_tibble %>%
add_column(trail_id = trail_id) %>%
add_column(contrast_left = session[[session_id]]$contrast_left[trail_id]) %>%
add_column(contrast_right = session[[session_id]]$contrast_right[trail_id]) %>%
add_column(feedback_type = session[[session_id]]$feedback_type[trail_id])
return(trail_tibble)
}
# Test function
trail_tibble_1_2 <- get_trail_data(1,2)
trial_counts <- sapply(session, function(x) length(x$feedback_type))
neuron_counts <- sapply(session, function(x) length(unique(x$brain_area)))
brain_area_counts <- sapply(session, function(x) length(unique(x$brain_area)))
# Create a summary table
eda_summary <- data.frame(
session_ID = 1:18,
num_trials = trial_counts,
num_neurons = neuron_counts,
num_brain_areas = brain_area_counts
)
# print(eda_summary)
muted_colors <- c( "#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FDBF6F", "#FF7F00",
"#C6DBEF", "#6BAED6", "#D9F0A3", "#78C679", "#FDD49E", "#FE9929",
"#FC9272", "#DE2D26", "#E5F5E0", "#A1D99B", "#FFD700", "#FFA500"
)
ggplot(eda_summary, aes(x = factor(session_ID), y = num_trials, fill = factor(session_ID))) +
geom_bar(stat = "identity") +
scale_fill_manual(values = muted_colors) +
labs(title = "Number of Trials Per Session", x = "Session ID", y = "Number of Trials") +
theme_minimal()
# Prepare data: Count the number of neurons per brain area per session
brain_area_per_session <- data.frame(
session_ID = rep(1:18, times = sapply(session, function(x) length(x$brain_area))),
brain_area = unlist(lapply(session, function(x) x$brain_area))
) %>%
group_by(session_ID, brain_area) %>%
summarise(num_neurons = n(), .groups = "drop")
# Plot heatmap
ggplot(brain_area_per_session, aes(x = factor(session_ID), y = brain_area, fill = factor(session_ID))) +
geom_tile() +
scale_fill_manual(values = muted_colors) +  # Assign muted colors per session
labs(title = "Neuron Counts Per Brain Area Across Sessions",
x = "Session ID", y = "Brain Area", fill = "Session") +
theme_minimal()
# Initialize an empty dataframe to store results
session_success <- tibble(
session_ID = integer(),
total_trials = integer(),
successful_trials = integer(),
success_percentage = numeric()
)
# Loop through each session and calculate success percentage
n.session <- length(session)
for(i in 1:n.session){
tmp <- session[[i]]  # Extract session data
# Ensure feedback_type exists in the session data
if(!is.null(tmp$feedback_type) && length(tmp$feedback_type) > 0) {
total_trials <- length(tmp$feedback_type)  # Count total trials
successful_trials <- sum(tmp$feedback_type == 1)  # Count successes
# Compute success percentage safely
success_percentage <- ifelse(total_trials > 0, (successful_trials / total_trials) * 100, 0)
# Store results
session_success <- bind_rows(session_success, tibble(
session_ID = i,
total_trials = total_trials,
successful_trials = successful_trials,
success_percentage = success_percentage
))
}
}
print(session_success)
# Initialize an empty dataframe to store results
session_success <- tibble(
session_ID = integer(),
total_trials = integer(),
successful_trials = integer(),
success_percentage = numeric()
)
# Loop through each session and calculate success percentage
n.session <- length(session)
for(i in 1:n.session){
tmp <- session[[i]]  # Extract session data
# Ensure feedback_type exists in the session data
if(!is.null(tmp$feedback_type) && length(tmp$feedback_type) > 0) {
total_trials <- length(tmp$feedback_type)  # Count total trials
successful_trials <- sum(tmp$feedback_type == 1)  # Count successes
# Compute success percentage safely
success_percentage <- ifelse(total_trials > 0, (successful_trials / total_trials) * 100, 0)
# Store results
session_success <- bind_rows(session_success, tibble(
session_ID = i,
total_trials = total_trials,
successful_trials = successful_trials,
success_percentage = success_percentage
))
}
}
print(session_success)
# Initialize an empty dataframe to store results
session_success <- tibble(
session_ID = integer(),
total_trials = integer(),
successful_trials = integer(),
success_percentage = numeric()
)
# Loop through each session and calculate success percentage
n.session <- length(session)
for(i in 1:n.session){
tmp <- session[[i]]  # Extract session data
# Ensure feedback_type exists in the session data
if(!is.null(tmp$feedback_type) && length(tmp$feedback_type) > 0) {
total_trials <- length(tmp$feedback_type)  # Count total trials
successful_trials <- sum(tmp$feedback_type == 1)  # Count successes
# Compute success percentage safely
success_percentage <- ifelse(total_trials > 0, (successful_trials / total_trials) * 100, 0)
# Store results
session_success <- bind_rows(session_success, tibble(
session_ID = i,
total_trials = total_trials,
successful_trials = successful_trials,
success_percentage = success_percentage
))
}
}
print(session_success)
session_success <- session_success %>%
mutate(mouse_name = case_when(
session_ID %in% 1:3 ~ "Cori",
session_ID %in% 4:7 ~ "Forssmann",
session_ID %in% 8:11 ~ "Hench",
session_ID %in% 12:18 ~ "Lederberg"
))
ggplot(session_success, aes(x = factor(session_ID), y = success_percentage, fill = mouse_name)) +
geom_bar(stat = "identity") +
scale_fill_manual(values = c("Cori" = "#A6CEE3",
"Forssmann" = "#B2DF8A",
"Hench" = "#FDBF6F",
"Lederberg" = "#DE2D26")) +  # Assign specific colors per mouse
labs(title = "Success Percentage Per Session (Grouped by Mouse)",
x = "Session ID",
y = "Success Percentage (%)",
fill = "Mouse") +
theme_minimal() +
geom_text(aes(label = round(success_percentage, 1)), vjust = -0.5, size = 4)
mouse_success <- session_success %>%
group_by(mouse_name) %>%
summarise(avg_success_rate = mean(success_percentage, na.rm = TRUE))
ggplot(mouse_success, aes(x = mouse_name, y = avg_success_rate, fill = mouse_name)) +
geom_bar(stat = "identity") +
scale_fill_manual(values = c("Cori" = "#A6CEE3",
"Forssmann" = "#B2DF8A",
"Hench" = "#FDBF6F",
"Lederberg" = "#DE2D26")) +  # Assign colors per mouse
labs(title = "Average Success Percentage Per Mouse",
x = "Mouse",
y = "Average Success Percentage (%)",
fill = "Mouse") +
theme_minimal() +
geom_text(aes(label = round(avg_success_rate, 1)), vjust = -0.5, size = 5)
trial_counts <- sapply(session, function(x) length(x$feedback_type))
# Create a DataFrame
trial_df <- data.frame(
session_ID = 1:18,
num_trials = trial_counts
)
# Graph
ggplot(trial_df, aes(x = factor(session_ID), y = num_trials, fill = factor(session_ID))) +
geom_bar(stat = "identity") +
scale_fill_manual(values = muted_colors) +  # Apply custom color palette
labs(title = "Number of Trials Per Session",
x = "Session ID", y = "Number of Trials", fill = "Session ID") +
theme_minimal() +
geom_text(aes(label = num_trials), vjust = -0.5, size = 4)
trial_per_mouse <- data.frame(
session_ID = 1:18,
mouse_name = sapply(session, function(x) unique(x$mouse_name)),  # Extract unique mouse names
num_trials = sapply(session, function(x) length(x$feedback_type))
)
# Aggregate the total number of trials per mouse
mouse_trial_counts <- trial_per_mouse %>%
group_by(mouse_name) %>%
summarise(total_trials = sum(num_trials))
# Define mouse-specific colors (ensure these match previous graphs)
mouse_colors <- c(
"Cori" = "#A6CEE3",       # Light Blue
"Forssmann" = "#B2DF8A",  # Light Green
"Hench" = "#FDBF6F",      # Orange
"Lederberg" = "#DE2D26"   # Dark Orange
)
# Graph with correctly mapped colors
ggplot(mouse_trial_counts, aes(x = mouse_name, y = total_trials, fill = mouse_name)) +
geom_bar(stat = "identity") +
scale_fill_manual(values = mouse_colors) +  # Explicitly assign colors per mouse
labs(title = "Number of Trials Per Mouse",
x = "Mouse Name", y = "Total Number of Trials", fill = "Mouse") +
theme_minimal() +
geom_text(aes(label = total_trials), vjust = -0.5, size = 5)
# Define mice session groups
mice_sessions <- list(
"Cori" = 1:3,
"Forssmann" = 4:7,
"Hench" = 8:11,
"Lederberg" = 12:18
)
# Function to extract and process spiking data
process_spikes <- function(sessions, mouse_name) {
# Extract spiking data for all trials in selected sessions
spike_data <- rbindlist(lapply(sessions, function(i) {
trials <- seq_along(session[[i]]$spks)  # Get all trials in session
# Flatten and extract all trials for session `i`
rbindlist(lapply(trials, function(t) {
mat <- as.data.table(session[[i]]$spks[[t]])  # Convert matrix to data.table
mat[, neuron := .I]  # Create neuron index column
mat <- melt(mat, id.vars = "neuron", variable.name = "time_bin", value.name = "spike_count")  # Wide to long
mat[, `:=`(feedback_type = session[[i]]$feedback_type[t], session_ID = i, mouse_name = mouse_name)]
return(mat)
}))
}))
# Convert time_bin (V1, V2...) to numeric
spike_data[, time_bin := as.numeric(gsub("V", "", time_bin))]
# Compute average spike count per time bin for each feedback type
psth_data <- spike_data[, .(avg_spike_count = mean(spike_count, na.rm = TRUE)), by = .(time_bin, feedback_type)]
return(psth_data)
}
# Generate PSTH plots for each mouse
psth_plots <- lapply(names(mice_sessions), function(mouse) {
psth_data <- process_spikes(mice_sessions[[mouse]], mouse)
ggplot(psth_data, aes(x = time_bin, y = avg_spike_count, color = factor(feedback_type))) +
geom_line(size = 1) +
scale_color_manual(values = c("#DE2D26", "#1F78B4"), labels = c("Failure", "Success")) +
labs(title = paste("Peri-Stimulus Time Histogram (PSTH) -", mouse),
x = "Time Bins", y = "Average Spike Count", color = "Feedback Type") +
theme_minimal()
})
